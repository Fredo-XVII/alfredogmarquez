---
title: "Spark Installation on Windows"
author: "Alfredo G Marquez"
date: '2018-05-04'
slug: spark-installation-on-windows
tags: 
  - Spark
  - SparkR
  - installation
  - windows
categories:
- Spark
- SparkR
keywords:
- SparkR
- Spark
- Windows
- Installation
autoThumbnailImage: false
thumbnailImagePosition: "top"
thumbnailImage: https://upload.wikimedia.org/wikipedia/commons/f/f3/Apache_Spark_logo.svg
coverImage: https://upload.wikimedia.org/wikipedia/commons/f/f3/Apache_Spark_logo.svg
metaAlignment: center
coverMeta: out
summary: "Today I will discuss how to install Apache Spark onto a Windows machine."
draft: true
---



<div id="intro" class="section level1">
<h1>Intro</h1>
<blockquote>
<p>Today I will discuss how to install Apache Spark onto a Windows machine. I have just walked through the process a second time at work due to a laptop swap and it takes me sometime to remember all the steps to get the install right, so I thought I would document the process.</p>
</blockquote>
<pre class="md"><code>&lt;!--more--&gt;</code></pre>
<hr />
</div>
<div id="download-and-installation" class="section level1">
<h1>Download and Installation</h1>
<p><strong>Install Spark</strong> First you will need to download Spark, which comes with the package for SparkR. Note, as of this posting, the SparkR package was removed from CRAN, so you can only get SparkR from the Apache website. Spark can be downloaded directly from Apache <a href="http://spark.apache.org/downloads.html">here</a>.</p>
<p>After downloading, save the zipped file to a directory of choice, and then unzip the file. I have an Apps (C:) folder where I put all the software that I download and install. This make it easy to transition to another laptop as all I have to do is go down the list installing software. I changed/shortened the folder name for simplicity and ease of typing.</p>
<p><img src="/images/Apache_folder.png" /><!-- --> <br></br></p>
<p><strong>Install Java</strong></p>
<p>As of this writing, Java 9 has been having a ton of issues and is not stable. I was able to use the most recent version of Java 8. You can download the most recent version for Windows at this <a href="http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html">link</a>. You have to accept their license agreement before downloadning.</p>
<p>Unlike Spark, I will let the system determine where to install Java. I feel like this works best to reduce future issues.</p>
<p><strong>Install WINUTILS_HOME</strong></p>
<p>This step tripped me up for a long time when I first started to learning about Spark. Not many blog posts would talk about installing these feature. I am not really sure what it does, but if you want more information here is the <a href="https://wiki.apache.org/hadoop/WindowsProblems">ApacheWiki</a>.</p>
</div>
<div id="we-can-then-set-up-spark-in-r-environment." class="section level1">
<h1>We can then set up Spark in R environment.</h1>
</div>
<div id="set-system-environmental-variables-to-run-spark-either-in-windows-or-r" class="section level1">
<h1>Set system environmental variables to run Spark (either in windows, or R):</h1>
<p>## SPARK_HOME: Sys.setenv(SPARK_HOME = “C:\Apps\Apache\Spark\spark-2.3.0\bin”)</p>
<p>## SPARKR_DRIVER_R: R_HOME from sys.getenv</p>
<p>## JAVA_HOME:</p>
<p>## WINUTILS_HOME:</p>
</div>
<div id="testing-install" class="section level1">
<h1>Testing Install</h1>
</div>
<div id="references" class="section level1">
<h1>References</h1>
<ul>
<li>RPubs : <a href="https://rpubs.com/wendyu/sparkr" class="uri">https://rpubs.com/wendyu/sparkr</a></li>
</ul>
</div>
<div id="set-library-path-and-load-sparkr-library" class="section level1">
<h1>Set library path and load SparkR library</h1>
<p>.libPaths(c(file.path(Sys.getenv(“SPARK_HOME”), “R”, “lib”), .libPaths())) library(SparkR)</p>
</div>
<div id="this-script-for-running-spark-code-from-the-r-console-or-rstudio" class="section level1">
<h1>This script for running Spark code from the R Console, or Rstudio</h1>
<p>Sys.getenv() # ensure the environmental variables are set as stated above</p>
<p>library(SparkR, lib.loc = c(file.path(Sys.getenv(“SPARK_HOME”), “R”, “lib”)))</p>
</div>
<div id="note-did-not-run-start-up-file-to-get-this-to-workstart_up-changes-the-java-directory-dont-forget" class="section level1">
<h1>note: did not run Start up file to get this to work…start_up changes the Java directory, don’t forget!!!!</h1>
</div>
<div id="java-make-sure-that-you-set-the-java-directory-with-jre---is-working-currently-version-java8-is-working." class="section level1">
<h1>Java: make sure that you set the Java directory with JRE - is working, currently version Java8 is working.</h1>
<p>sparkR.session(enableHiveSupport = FALSE , master = “local[*]”, sparkHome = Sys.getenv(“SPARK_HOME”) , # this was the missing link!! sparkConfig = list(spark.driver.memory = “2g”, spark.sql.warehouse.dir=“C:\Apps\winutils\winutils-master\hadoop-2.7.1”) # winutils path directory )</p>
<p>df &lt;- as.DataFrame(faithful) str(df) colnames(df) histogram(df$waiting)</p>
<p>createOrReplaceTempView(df, “df”)</p>
<p>waiting_70 &lt;- sql(“select * from df where waiting &gt; 70”) str(waiting_70) collect(waiting_70)</p>
<p>collect(summary(df))</p>
<p>corr(df, “waiting”, “eruptions”)</p>
<p>model &lt;- spark.glm(df, eruptions ~ waiting) summary(model)</p>
<hr />
<p>Kuddos for the Spark image goes to:</p>
<pre class="md"><code>&gt;  - Apache software foundation - https://spark.apache.org/images/spark-logo.eps, Apache License 2.0, https://commons.wikimedia.org/w/index.php?curid=57832155</code></pre>
</div>
