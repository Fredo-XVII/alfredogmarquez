---
title: R's Demise Higly Overblown
author: Alfredo G Marquez
date: '2019-11-11'
categories:
  - R
tags:
  - R Programming Cranlogs trends popularity
slug: r-s-demise-higly-overblown
keywords:
  - R
  - popular
  - popularity
  - trends
autoThumbnailImage: no
thumbnailImagePosition: top
thumbnailImage: https://www.r-project.org/logo/Rlogo.svg
coverImage: 
metaAlignment: center
coverMeta: out
coverSize: partial
summary: Today I will provide evidence that R's demise are highly overblown.
draft: false
---

<!--more-->


# 

In this post I will provide evidence that contradicts recent reports that the R Programming language is declining in popularity.

-----

In last few months I have come across several blog posts that suggest that Python is reducing the demand for R. Yet, it contradicts what I am seeing in my day to day life.  Many analyst at work from different parts of the business that are not associated with data science or software engineering are adopting the R programming language because it feels more comfortable than Python and they are not interested in building software or building production pipelines.  These souls are highly ignored by the software community, but they are embraced by the R community because at the end of the day we just care about the data and the stories that they tell, and R is great for telling stories.

-----

# Introduction

As I have read all these posts about python impacting the demand for R and implying that R was on the decline, I though about how I could address this question empirically.  I thought to myself, if the rise in Python for Data Science is decreasing the demand for R for Data Science, then naturally, you would see a decrease in R downloads as users moved from R to Python.  Therefore, my experiment is designed as below:

#### **Design of Experiment:**

> **Null Hypothesis (H0):** No change to R downloads, given the rise in Python.
>
> **Alternative Hypothesis (H1):** R downloads decline, given the rise in Python.
>
> **Basic Assumption:** R downloads are conducted by users intending to use the language. In other words, users are not downloading R just because they enjoy downloading stuff; they actually intend to use the download.

# Data

Ideally, I would collect the number of times R is download from the CRAN mirrors, as well as, collect the number of times Python is downloaded over time.  My thought was to start the analysis from 2015 to the present in order to capture the rise of both languages.  From this point, you can conduct Granger Causality Test to see if Python is truly impacting the demand for R.  Unfortunately, I was not able to find a downloadable count of Python downloads since 2015.  I did find a page that provide the last 30 days of download statistics, but nothing that you can download that was relevant to this exercise.  

R fared a little better but not much.  CRAN has many mirrors around the world that are self hosted.  In other words, unless the mirror owners publish there download history, there is no way to know how many times R is being downloaded.  Luckily, @RStudio has provided a way to obtain the downloads of R from there mirror in the R package **cranlogs**.

The **cranlogs** package not only gives you downloads for R itself, but also for packages that are downloaded from the @RStudio cran mirror.  Because @RStudio has an easy GUI interface for downloading packages, and is extremely popular among R users, I will assume that a majority of the package downloads are downloaded by users using @RStudio as an IDE. 

In contrast, I will not make the same assumption about installing R itself.  Normally, I install R core from the https://www.r-project.org/ website and then I install @RStudio IDE. This is important because I will use the @RStudio R downloads as a proxy of R downloads.



# Analysis

To begin my analysis, I will use the packages loaded below.  

```{r libaries, results='hide', message=FALSE}
# Libraries
library(cranlogs)
library(lubridate)
library(gridExtra)
#library(ggrepel)
library(tidyverse)
library(tsibble)
library(gtrendsR)
library(rversions)
library(scales)
library(kableExtra)

# Options
options(scipen = 999)
```


### Build Data

In this section I will download 2 datasets.  The first will be the R downloads from the **cranlogs** package, and the second will be data from the **rversions** package in order to get R version release dates.  The version dates data will be used to label the graphs.
```{r, echo=FALSE}
# Download R download data and version dates
R_ver_hist_raw <- rversions::r_versions() 
R_ver_hist_raw$vers_d <- as.POSIXct(R_ver_hist_raw$date)

R_ver_hist <- R_ver_hist_raw %>% dplyr::select(-date) %>% 
  dplyr::mutate(greg_d = lubridate::as_date(vers_d),
                vers_i = forcats::as_factor(version),
                nickname = forcats::as_factor(nickname),
                yr_wk_ver = tsibble::yearweek(as.Date(greg_d))
  ) %>% 
  dplyr::select(version,vers_i,nickname,greg_d,yr_wk_ver) %>% 
  dplyr::filter(greg_d >= as.Date('2015-01-01')) 

R_ver_hist_major <- R_ver_hist %>%  
  dplyr::filter(vers_i %in% c("3.2.0","3.3.0","3.4.0","3.5.0","3.6.0"))

#cran_R_downloads_raw <- cranlogs::cran_downloads('R', from = "2010-01-01", to = lubridate::today())
cran_R_downloads_raw <- readRDS(file = paste0("C:\\Users\\marqu\\OneDrive\\Documents\\blog\\alfredogmarquez\\data", "\\cran_R_downloads_raw.rds"))

cran_R_downloads <- cran_R_downloads_raw %>% 
  dplyr::filter(!version %in% c('devel','release','release.exe','latest')) %>% 
  dplyr::mutate(os_factor = forcats::fct_inorder(forcats::as_factor(os)),
         ver_factor =forcats::fct_inorder(forcats::as_factor(version)),
         ver_lvl = sub("*[.^]", "", version) %>% sub("\\..*", "", .) %>% as.integer(),
         ver_lvl_factor =forcats::fct_inorder(forcats::as_factor(ver_lvl)),
         ver_lvl_top = stringr::str_sub(version,1,1) %>% as.integer(),
         ver_lvl_top_factor =forcats::fct_inorder(forcats::as_factor(ver_lvl_top)),
         year = lubridate::year(date),
         month = lubridate::month(date),
         week = lubridate::week(date),
         yr_mo = tsibble::yearmonth(date),
         yr_wk = tsibble::yearweek(date),
         ver_3_5_f = ifelse(date >= subset(R_ver_hist_major, version == '3.5.0')$greg_d,1,0)
  ) %>% 
  dplyr::filter(yr_wk != max(.$yr_wk)) %>% 
  dplyr::left_join(R_ver_hist, by = c("yr_wk" = "yr_wk_ver")) 
```

Here is a quick look at the data.  I created some new features, date factors and period dummy variables, in order to drill into the data graphically.
```{r}
tail(cran_R_downloads,10) %>% knitr::kable() %>% kableExtra::kable_styling()
```


# EDA and Understanding the Data

### Yearly View
I was first curious about the overall trend of the data. You can see that R downloads decreased from 2015 to 2016, recovering in 2017 but about 1 million downloads short from its 2015 level.  Then in 2018 R downloads grow by 2 million downloads, or 23%, to 10 million and surpasses its 2015 level by 1 million downloads.  Finally, R downloads have grown by almost 50% to 15 million downloads this year.  I have to admit those totals are more than I would have thought.  This growth might explain why the Michigan CRAN mirror has added a second CRAN mirror; the Michigan Mirror being the closet to my location.  In any case, this evidence contradicts the suggestion that Python is having a negative impact on the adoption of R.

```{r, echo=FALSE, warning=FALSE}
# Build Aggregation Views
# What does the trend look at by Year
down_tot_by_yr <- cran_R_downloads %>% 
  dplyr::group_by(year) %>% 
  dplyr::summarise(total = sum(count)) %>% 
  dplyr::mutate(yoy = total/dplyr::lag(total),
                yoy_perc = (total/dplyr::lag(total) - 1)*100,
                ) %>% 
  tsibble::as_tsibble(index = year) 

g_tot_by_yr <- down_tot_by_yr %>% 
  ggplot(aes(x = year, y = total, color = year)) +
  geom_line() +
  theme_light() + theme(legend.position = "none") +
  xlim(2015, 2020) +
  labs(x = 'Year', y = 'Total Downloads', title = "R Downloads from RStudio Cranlogs by Year") +
  scale_y_continuous(labels = scales::unit_format(unit = "M", scale = 1e-05, digits = 4))


g_tot_by_yoy <- down_tot_by_yr %>% 
  ggplot(aes(x = year, y = yoy_perc, fill = yoy_perc)) +
  geom_col() +
  theme_light() + theme(legend.position = "none") +
  xlim(2015, 2020) +
  annotate(geom = "text", 
           x=down_tot_by_yr$year, 
           y=0, 
           label=paste0(round(down_tot_by_yr$yoy_perc,0),'%'),
           size=5, angle=0, vjust= -.25, hjust= 0.50) +
  labs(x = 'Year', y = 'YOY % Growth') +
  scale_y_continuous(labels = scales::percent_format(scale = 1))

gridExtra::grid.arrange(g_tot_by_yr,g_tot_by_yoy)

```


At this point, I could probably be done because I think that there is sufficient evidence to support that the growth in R is not being negatively impacted by the growth in Python. But there are some other interesting variables in the data that I would like to explore.  

### Weekly View by Operating System (OS)

```{r, echo=FALSE}
# What does the trend look like by os
down_tot_by_os <- cran_R_downloads %>% 
  dplyr:: group_by(os_factor,yr_wk) %>% 
  dplyr::summarise(total = sum(count)) %>% 
  dplyr::mutate(yoy = total/dplyr::lag(total, n = 52),
                yoy_perc = (total/dplyr::lag(total,n = 52) - 1)*100
  )

g_os_lvl <- down_tot_by_os %>% 
  ggplot(aes(x = yr_wk, y = total, col = os_factor, group = os_factor)) +
  geom_line() +
  facet_grid(os_factor~., scales = 'free') +
  scale_x_date(date_breaks = "1 year", date_labels = "%Y") +
  geom_vline(data = R_ver_hist, aes(xintercept = yr_wk_ver), linetype = 4, color = "red", alpha = 0.5) +
  geom_vline(data = R_ver_hist_major, aes(xintercept = greg_d), linetype = 1, color = "blue") +
  annotate(geom = "text", 
         x=subset(R_ver_hist_major, version == '3.5.0')$yr_wk, 
         y=0, label=subset(R_ver_hist_major, version == '3.5.0')$version,
         size=4, angle=90, vjust=-0.10, hjust=-0.10,  color = "blue", alpha = 0.75) +
  annotate(geom = "text", 
           x=subset(R_ver_hist, version == '3.5.1')$yr_wk, 
           y=0, label=subset(R_ver_hist, version == '3.5.1')$version,
           size=4, angle=90, vjust=-0.10, hjust=-0.10,  color = "red", alpha = 0.5) +
  theme_light() + theme(legend.position = "none") +
  labs(x = 'Week', y = '', title = "R Downloads from RStudio Cranlogs by Week",
       caption = "
       Current R major version is 3.x.x \n
       Blue Line: R minor version releases\n
       Red Dotted Line: R version patches \n       .
       ")
#g_os_lvl

g_os_yoy <- down_tot_by_os %>% 
  ggplot(aes(x = yr_wk, y = yoy_perc, col = os_factor, group = os_factor)) +
  #geom_line() +
  geom_col() +
  scale_y_continuous(labels = scales::percent_format(scale = 1)) +
  facet_grid(os_factor~., scales = 'free') +
  geom_hline(yintercept = 0) +
  scale_x_date(date_breaks = "1 year", date_labels = "%Y") +
  geom_vline(data = R_ver_hist, mapping = aes(xintercept = greg_d), linetype = 4, color = "red", alpha = 0.5) +
  geom_vline(data = R_ver_hist_major, aes(xintercept = greg_d), linetype = 1, color = "blue") +
  annotate(geom = "text", 
           x=subset(R_ver_hist_major, version == '3.5.0')$yr_wk, 
           y=0, label=subset(R_ver_hist_major, version == '3.5.0')$version,
           size=4, angle=90, vjust=-0.10, hjust=-0.10,  color = "blue", alpha = 0.75) +
  annotate(geom = "text", 
           x=subset(R_ver_hist, version == '3.5.1')$yr_wk, 
           y=0, label=subset(R_ver_hist, version == '3.5.1')$version,
           size=4, angle=90, vjust=-0.10, hjust=-0.10,  color = "red", alpha = 0.5) +
  theme_light() + theme(legend.position = "none") +
  labs(x = 'Week', y = '', title = "R Downloads Year Over Year Change from RStudio Cranlogs by Week",
       caption = "
       Current R major version is 3.x.x \n
       Blue Line: R minor version releases\n
       Red Dotted Line: R version patches \n  
       ")
#g_os_yoy

#gridExtra::grid.arrange(g_os_lvl, g_os_yoy)

# Summary Stats
down_os_summary <- down_tot_by_os %>% dplyr::left_join(cran_R_downloads %>% select(yr_wk,ver_3_5_f),
                                    by = "yr_wk") %>% 
  dplyr::group_by(os_factor,ver_3_5_f) %>% summarise_all(mean,na.rm = TRUE)

# Function to grab metrics in writing
get_os_summary <- function(os, post351, metric) {
  down_os_summary %>% filter(os_factor == !!os,ver_3_5_f == !!post351) %>% 
    ungroup() %>% select(!!metric) %>% round()
}
```

One of the questions I had was where is the growth coming from in the last year? My first thought was to overlay the version releases for R; the blue line represents the minor version releases, and the red dotted line represents patch releases. There were no major releases during this time.  You can see right away that downloads start trending after the R 3.5 version release.  The R 3.5 release was a really big release with many upgrades to the internal components of R, with some changes that made R work faster.  However, you don't see the increase in downloads right away and that was because the upgrades had an issue where it wouldn't work with older versions of R packages.  This is normally why I wait for at least 1 patch release before installing R after a minor release.  For example, I have just now started to upgrade to R 3.6.x even though that minor release was in the fall of last year.

From the graphs below, we observe that the operating system (OS) with the most downloads/week is Windows, with an average of `r get_os_summary(os = 'win', post351 = 0, metric = 'total')` downloads/week before the release of R 3.5.1., and `r get_os_summary(os = 'win', post351 = 1, metric = 'total')` downloads/week post the R 3.5.1 release. I was pleasantly surprised to see that Windows was the leading OS for downloads.  Most software engineers that I know use Macs for their development, so who are all these windows users? My guess, and I have not evidence to support this, is that analyst on the business side that traditionally have used excel for their work are now picking up R for the day to day analysis.  Now R has a bad rap for having an uphill learning curve, but I believe with the tidyverse, this is no longer the case.  I will show some evidence to this point below.  I have easily brought people up to speed at work with just 2 packages, dplyr and ggplot2.  Basically, anything that they can do in excel, now they can do with R, and more.

My second surprise from looking at the OS break out was the large increase in Mac users.  I am not sure why this would be the case except that Macs are now more common at work.  For a long time it was very difficult to request a Mac at work, but over the last 3 years or so, it has been much easier to obtain a Mac if you so desire.  If this is happening across industries, then this may explain some of this growth in addition to the university effect where Mac seems to be quite common.  R downloads for Mac averaged `r get_os_summary(os = 'osx', post351 = 0, metric = 'total')` in the period before the R 3.5.1 release and has averaged `r get_os_summary(os = 'osx', post351 = 1, metric = 'total')`, more than doubling its weekly average downloads.  The upward trend for Mac R downloads doesn't seem to waning so there may be growth to come over the next year.

Finally, I will not discuss the OS labeled "NA" as it is really small, I just present it for completeness.  I was not able to determine if the OS for "SRC" was building R from source, or whether it was for Linux.  In any case, R downloads for "SRC" have been consistent throughout the entire time frame with some large growth after the R 3.5.2 release.  The average download for "SRC" is `r get_os_summary(os = 'src', post351 = 0, metric = 'total')` in the period before R 3.5.1 release and `r get_os_summary(os = 'src', post351 = 1, metric = 'total')` after.



```{r wkly_trend_os, fig.hieght=10, fig.asp= .67, echo=FALSE, warning=FALSE}
g_os_lvl

```


In this section, I will quickly describe the year over year (YOY) growth in R downloads for each type of operating system.  The average weekly YOY growth rate for Windows for the pre-period is `r paste0(get_os_summary(os = 'win', post351 = 0, metric = 'yoy_perc'),'%')` and `r paste0(get_os_summary(os = 'win', post351 = 1, metric = 'yoy_perc'), '%')` for the post period.  The average weekly YOY growth rate for Mac for the pre-period is `r paste0(get_os_summary(os = 'osx', post351 = 0, metric = 'yoy_perc'),'%')` and `r paste0(get_os_summary(os = 'osx', post351 = 1, metric = 'yoy_perc'), '%')` for the post period.  The average weekly YOY growth rate for Windows for the pre-period is `r paste0(get_os_summary(os = 'src', post351 = 0, metric = 'yoy_perc'),'%')` and `r paste0(get_os_summary(os = 'src', post351 = 1, metric = 'yoy_perc'), '%')` for the post period.  Imagine for a second if you were a product manager, and your product was experiencing 80% plus growth on average every week for nearly 2 years; how ecstatic would you be?



```{r yoy_growth_os, fig.hieght=10, fig.asp= .67, echo=FALSE, warning=FALSE}
g_os_yoy
```


# The Problems with Using Search Trends

The problem using search trends to make predictions is that it makes large assumptions that your consumer remains static which , or from the product perspective, consumers approach their searches of the R Programming language the same regardless of where the R Programming language is in its product life cycle.  For example, the TIOBE Index uses **+"<language> programming"** for its search query and then counts the hits generated from dozens of search engines, and finally applies a standardization method (see references below).  So for R the search would be "R programming**  



# The Probability of Coincidences

# Reference

  - https://cran.r-project.org/web/packages/cranlogs/cranlogs.pdf
  - https://github.com/r-hub/cranlogs.app
  - Google Trend Results: https://trends.google.com/trends/explore?date=2010-01-01%202019-11-23&geo=US&q=%22R%20programming%22,Tidyverse,dplyr,ggplot2
  - TIOBE Index Definition: https://www.tiobe.com/tiobe-index/programming-languages-definition/
  - PYPL Index Definition: 


# Session Info
```{r}
sessionInfo()
```


