library(blogdown)
blogdown:::new_post_addin()
blogdown:::new_post_addin()
blogdown:::update_meta_addin()
serve_site()
serve_site()
build_site()
serve_site()
blogdown:::new_post_addin()
blogdown:::new_post_addin()
4385.00 * .5
blogdown::build_site(local = TRUE)
blogdown::build_site(local = TRUE)
blogdown::build_site(local = TRUE)
blogdown::build_site(local = TRUE)
blogdown::build_site(local = TRUE)
blogdown::build_site(local = TRUE)
blogdown::build_site(local = TRUE)
200/10
blogdown::build_site(local = TRUE)\
blogdown::build_site(local = TRUE)
blogdown::build_site(local = TRUE)
blogdown::build_site(local = TRUE)
blogdown::build_site(local = TRUE)
blogdown::build_site(local = TRUE)
blogdown::build_site(local = TRUE)
blogdown::build_site(local = TRUE)
blogdown::build_site(local = TRUE)
blogdown::build_site(local = TRUE)
blogdown::build_site(local = TRUE)
blogdown::build_site(local = TRUE)
blogdown::build_site(local = TRUE)
blogdown::build_site(local = TRUE)
blogdown::build_site(local = TRUE)
blogdown::build_site(local = TRUE)
blogdown::build_site(local = TRUE)
blogdown::build_site(local = TRUE)
blogdown::build_site(local = TRUE)
blogdown::build_site(local = TRUE)
blogdown::build_site(local = TRUE)
blogdown::build_site(local = TRUE)
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
library(blogdown)
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
Sys.getenv()
Sys.setenv(SPARK_HOME = "C:\\Apps\\Apache\\Spark\\spark-2.3.0\bin")
Sys.getenv()
Sys.setenv(SPARK_HOME = "C:\\Apps\\Apache\\Spark\\spark-2.3.0\\bin")
Sys.getenv()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
knitr::include_graphics("/img/Apache_folder.png")
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
knitr::include_graphics("/images/Apache_folder.png")
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
Sys.getenv("R_HOME")
cat(Sys.getenv("R_HOME"))
Sys.getenv()
path.expand(Sys.getenv("R_HOME"))
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
Sys.getenv()
.libPaths(c(file.path(Sys.getenv("SPARK_HOME"), "R", "lib"), .libPaths()))
library(SparkR)
blogdown::build_site()
blogdown::build_site()
Sys.getenv()
Sys.getenv()
blogdown::build_site()
.libPaths(c(file.path(Sys.getenv("SPARK_HOME"), "R", "lib"), .libPaths()))
library(SparkR)
blogdown::build_site()
library(SparkR, lib.loc = c(file.path(Sys.getenv("SPARK_HOME"), "R", "lib")))
blogdown::build_site()
sparkR.uiWebUrl()
blogdown::build_site()
sparkR.session(enableHiveSupport = FALSE ,
master = "local[*]",
sparkHome = Sys.getenv("SPARK_HOME") , # this was the missing link!!
sparkConfig =
list(spark.driver.memory = "2g",
spark.sql.warehouse.dir="C:\\Apps\\winutils\\winutils-master\\hadoop-2.7.1") # winutils path directory
)
sparkR.uiWebUrl()
df <- as.DataFrame(faithful)
str(df)
colnames(df)
histogram(df$waiting)
createOrReplaceTempView(df, "df")
waiting_70 <- sql("select * from df where waiting > 70")
str(waiting_70)
collect(waiting_70)
collect(summary(df))
corr(df, "waiting", "eruptions")
model <- spark.glm(df, eruptions ~ waiting)
summary(model)
blogdown::build_site()
sparkR.uiWebUrl()
blogdown::build_site()
sparkR.uiWebUrl()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
sparkR.uiWebUrl()
head(collect(waiting_70), 10)
blogdown::build_site()
sparkR.session.stop()
sparkR.session(enableHiveSupport = FALSE ,
master = "local[*]",
sparkHome = Sys.getenv("SPARK_HOME") , # this was the missing link!!
sparkConfig =
list(spark.driver.memory = "2g", spark.executor.memory = "2g",
spark.sql.warehouse.dir="C:\\Apps\\winutils\\winutils-master\\hadoop-2.7.1") # winutils path directory
)
sparkR.uiWebUrl()
sparkR.uiWebUrl()
sparkR.uiWebUrl()
df <- as.DataFrame(faithful)
str(df)
colnames(df)
sparkR.uiWebUrl()
sparkR.session.stop()
sparkR.uiWebUrl()
sparkR.session(appName = "Blog",
enableHiveSupport = FALSE ,
master = "local[*]",
sparkHome = Sys.getenv("SPARK_HOME") , # this was the missing link!!
sparkConfig =
list(spark.driver.memory = "2g", spark.executor.memory = "2g",
spark.sql.warehouse.dir="C:\\Apps\\winutils\\winutils-master\\hadoop-2.7.1") # winutils path directory
)
sparkR.uiWebUrl()
SparkR::sparkRHive.init()
?sparkR.uiWebUrl
sparkR.uiWebUrl("Blog")
sparkR.spark.session
?sparkR.session
sparkR.session.stop()
sparkR.session(appName = "Blog",
enableHiveSupport = FALSE ,
master = "local[*]",
sparkHome = Sys.getenv("SPARK_HOME") , # this was the missing link!!
sparkConfig =
list(spark.driver.memory = "2g" #, spark.executor.memory = "2g",
spark.sql.warehouse.dir="C:\\Apps\\winutils\\winutils-master\\hadoop-2.7.1") # winutils path directory
sparkR.session(appName = "Blog",
enableHiveSupport = FALSE ,
master = "local[*]",
sparkHome = Sys.getenv("SPARK_HOME") , # this was the missing link!!
sparkConfig =
list(spark.driver.memory = "2g", # spark.executor.memory = "2g",
spark.sql.warehouse.dir="C:\\Apps\\winutils\\winutils-master\\hadoop-2.7.1") # winutils path directory
)
sparkR.uiWebUrl()
sparkR.session.stop()
sparkR.session(#appName = "Blog",
enableHiveSupport = FALSE ,
master = "local[*]",
sparkHome = Sys.getenv("SPARK_HOME") , # this was the missing link!!
sparkConfig =
list(spark.driver.memory = "2g", # spark.executor.memory = "2g",
spark.sql.warehouse.dir="C:\\Apps\\winutils\\winutils-master\\hadoop-2.7.1") # winutils path directory
)
sparkR.uiWebUrl()
blogdown::build_site()
waiting_70 <- sql("select * from df where waiting > 70")
df <- as.DataFrame(faithful)
str(df)
colnames(df)
createOrReplaceTempView(df, "df")
waiting_70 <- sql("select * from df where waiting > 70")
str(waiting_70)
df %>% collect() %>%
ggplot(aes(x = waiting, y = eruptions)) +
geom_point()
library(tidyverse)
df %>% collect() %>%
ggplot(aes(x = waiting, y = eruptions)) +
geom_point()
library(tidyverse)
.libPaths(c(file.path(Sys.getenv("SPARK_HOME"), "R", "lib"), .libPaths()))
library(SparkR)
SparkR::sparkR.session.stop()
library(tidyverse)
.libPaths(c(file.path(Sys.getenv("SPARK_HOME"), "R", "lib"), .libPaths()))
library(SparkR)
library(SparkR, lib.loc = c(file.path(Sys.getenv("SPARK_HOME"), "R", "lib")))
sparkR.session(#appName = "Blog",
enableHiveSupport = FALSE ,
master = "local[*]",
sparkHome = Sys.getenv("SPARK_HOME") , # this was the missing link!!
sparkConfig =
list(spark.driver.memory = "2g", # spark.executor.memory = "2g",
spark.sql.warehouse.dir="C:\\Apps\\winutils\\winutils-master\\hadoop-2.7.1") # winutils path directory
)
sparkR.uiWebUrl()
df <- as.DataFrame(faithful)
str(df)
colnames(df)
createOrReplaceTempView(df, "df")
waiting_70 <- sql("select * from df where waiting > 70")
str(waiting_70)
head(SparkR::collect(waiting_70), 10)
collect(summary(df))
SparkR::collect(SparkR::summary(df))
SparkR::corr(df, "waiting", "eruptions")
df %>% SparkR::collect() %>%
ggplot(aes(x = waiting, y = eruptions)) +
geom_point()
df %>% SparkR::collect() %>%
ggplot(aes(x = waiting, y = eruptions)) +
geom_point() +
geom_smooth()
head(df)
blogdown::build_site()
sparkR.uiWebUrl()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
waiting_avg <- SparkR::avg(df$waiting)
eruptions_avg <- SparkR::avg(df$eruptions)
df %>% SparkR::collect() %>%
ggplot(aes(x = waiting, y = eruptions)) +
geom_point() +
geom_smooth() +
geom_vline(xintercept = waiting_avg) +
geom_hline(yintercept = eruptions)
search()
waiting_avg <- SparkR::avg(df$waiting)
eruptions_avg <- SparkR::avg(df$eruptions)
df %>% SparkR::collect() %>%
ggplot(aes(x = waiting, y = eruptions)) +
geom_point() +
geom_smooth() +
geom_vline(xintercept = waiting_avg) +
geom_hline(yintercept = eruptions_avg)
waiting_avg <- SparkR::avg(df$waiting) %>% SparkR::collect()
waiting_avg
head(waiting_avg)
SparkR::avg(df$waiting)
head(SparkR::avg(df$waiting))
str(sf)
str(df)
avg(df$waiting)
collect(avg(df$waiting) )
SparkR::collect(avg(df$waiting) )
mean(df$eruptions)
head(df)
SparkR::avg(df,"waiting")
SparkR::collect(df$waiting) %>% mean()
collect(df$waiting)
waiting_avg <- SparkR::mean(df$waiting)
waiting_avg
waiting_avg <- SparkR::mean(df$waiting) %>% SparkR::collect()
SparkR::select(mean(df$waiting))
SparkR::select(SparkR::mean(df$waiting)) %>% SparkR::collect()
waiting_avg <- SparkR::select(df, SparkR::mean(df$waiting)) %>% SparkR::collect()
waiting_avg
waiting_avg <- SparkR::select(df, SparkR::mean(df$waiting)) %>% SparkR::collect()
eruptions_avg <- SparkR::select(df, SparkR::mean(df$eruptions)) %>% SparkR::collect()
df %>% SparkR::collect() %>%
ggplot(aes(x = waiting, y = eruptions)) +
geom_point() +
geom_smooth() +
geom_vline(xintercept = waiting_avg) +
geom_hline(yintercept = eruptions_avg)
waiting_avg
str(waiting_avg)
waiting_avg <- SparkR::select(df, SparkR::mean(df$waiting)) %>% SparkR::collect()
eruptions_avg <- SparkR::select(df, SparkR::mean(df$eruptions)) %>% SparkR::collect()
df %>% SparkR::collect() %>%
ggplot(aes(x = waiting, y = eruptions)) +
geom_point() +
geom_smooth() +
geom_vline(xintercept = waiting_avg$avg(waiting)) +
geom_hline(yintercept = eruptions_avg$`avg(eruptions)`)
waiting_avg <- SparkR::select(df, SparkR::mean(df$waiting)) %>% SparkR::collect()
eruptions_avg <- SparkR::select(df, SparkR::mean(df$eruptions)) %>% SparkR::collect()
df %>% SparkR::collect() %>%
ggplot(aes(x = waiting, y = eruptions)) +
geom_point() +
geom_smooth() +
geom_vline(xintercept = waiting_avg$`avg(waiting)`) +
geom_hline(yintercept = eruptions_avg$`avg(eruptions)`)
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
SparR::spark.session.stop
SparR::spark.session.stop()
SparkR::spark.session.stop()
SparkR::sparkR.session.stop()
rm(list=ls())
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
