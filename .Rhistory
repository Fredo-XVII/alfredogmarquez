blogdown::build_site(local = TRUE)
blogdown::build_site(local = TRUE)
blogdown::build_site(local = TRUE)
blogdown::build_site(local = TRUE)
blogdown::build_site(local = TRUE)
blogdown::build_site(local = TRUE)
blogdown::build_site(local = TRUE)
blogdown::build_site(local = TRUE)
blogdown::build_site(local = TRUE)
blogdown::build_site(local = TRUE)
blogdown::build_site(local = TRUE)
blogdown::build_site(local = TRUE)
blogdown::build_site(local = TRUE)
blogdown::build_site(local = TRUE)
blogdown::build_site(local = TRUE)
blogdown::build_site(local = TRUE)
blogdown::build_site(local = TRUE)
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
library(blogdown)
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
Sys.getenv()
Sys.setenv(SPARK_HOME = "C:\\Apps\\Apache\\Spark\\spark-2.3.0\bin")
Sys.getenv()
Sys.setenv(SPARK_HOME = "C:\\Apps\\Apache\\Spark\\spark-2.3.0\\bin")
Sys.getenv()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
knitr::include_graphics("/img/Apache_folder.png")
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
knitr::include_graphics("/images/Apache_folder.png")
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
Sys.getenv("R_HOME")
cat(Sys.getenv("R_HOME"))
Sys.getenv()
path.expand(Sys.getenv("R_HOME"))
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
Sys.getenv()
.libPaths(c(file.path(Sys.getenv("SPARK_HOME"), "R", "lib"), .libPaths()))
library(SparkR)
blogdown::build_site()
blogdown::build_site()
Sys.getenv()
Sys.getenv()
blogdown::build_site()
.libPaths(c(file.path(Sys.getenv("SPARK_HOME"), "R", "lib"), .libPaths()))
library(SparkR)
blogdown::build_site()
library(SparkR, lib.loc = c(file.path(Sys.getenv("SPARK_HOME"), "R", "lib")))
blogdown::build_site()
sparkR.uiWebUrl()
blogdown::build_site()
sparkR.session(enableHiveSupport = FALSE ,
master = "local[*]",
sparkHome = Sys.getenv("SPARK_HOME") , # this was the missing link!!
sparkConfig =
list(spark.driver.memory = "2g",
spark.sql.warehouse.dir="C:\\Apps\\winutils\\winutils-master\\hadoop-2.7.1") # winutils path directory
)
sparkR.uiWebUrl()
df <- as.DataFrame(faithful)
str(df)
colnames(df)
histogram(df$waiting)
createOrReplaceTempView(df, "df")
waiting_70 <- sql("select * from df where waiting > 70")
str(waiting_70)
collect(waiting_70)
collect(summary(df))
corr(df, "waiting", "eruptions")
model <- spark.glm(df, eruptions ~ waiting)
summary(model)
blogdown::build_site()
sparkR.uiWebUrl()
blogdown::build_site()
sparkR.uiWebUrl()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
sparkR.uiWebUrl()
head(collect(waiting_70), 10)
blogdown::build_site()
sparkR.session.stop()
sparkR.session(enableHiveSupport = FALSE ,
master = "local[*]",
sparkHome = Sys.getenv("SPARK_HOME") , # this was the missing link!!
sparkConfig =
list(spark.driver.memory = "2g", spark.executor.memory = "2g",
spark.sql.warehouse.dir="C:\\Apps\\winutils\\winutils-master\\hadoop-2.7.1") # winutils path directory
)
sparkR.uiWebUrl()
sparkR.uiWebUrl()
sparkR.uiWebUrl()
df <- as.DataFrame(faithful)
str(df)
colnames(df)
sparkR.uiWebUrl()
sparkR.session.stop()
sparkR.uiWebUrl()
sparkR.session(appName = "Blog",
enableHiveSupport = FALSE ,
master = "local[*]",
sparkHome = Sys.getenv("SPARK_HOME") , # this was the missing link!!
sparkConfig =
list(spark.driver.memory = "2g", spark.executor.memory = "2g",
spark.sql.warehouse.dir="C:\\Apps\\winutils\\winutils-master\\hadoop-2.7.1") # winutils path directory
)
sparkR.uiWebUrl()
SparkR::sparkRHive.init()
?sparkR.uiWebUrl
sparkR.uiWebUrl("Blog")
sparkR.spark.session
?sparkR.session
sparkR.session.stop()
sparkR.session(appName = "Blog",
enableHiveSupport = FALSE ,
master = "local[*]",
sparkHome = Sys.getenv("SPARK_HOME") , # this was the missing link!!
sparkConfig =
list(spark.driver.memory = "2g" #, spark.executor.memory = "2g",
spark.sql.warehouse.dir="C:\\Apps\\winutils\\winutils-master\\hadoop-2.7.1") # winutils path directory
sparkR.session(appName = "Blog",
enableHiveSupport = FALSE ,
master = "local[*]",
sparkHome = Sys.getenv("SPARK_HOME") , # this was the missing link!!
sparkConfig =
list(spark.driver.memory = "2g", # spark.executor.memory = "2g",
spark.sql.warehouse.dir="C:\\Apps\\winutils\\winutils-master\\hadoop-2.7.1") # winutils path directory
)
sparkR.uiWebUrl()
sparkR.session.stop()
sparkR.session(#appName = "Blog",
enableHiveSupport = FALSE ,
master = "local[*]",
sparkHome = Sys.getenv("SPARK_HOME") , # this was the missing link!!
sparkConfig =
list(spark.driver.memory = "2g", # spark.executor.memory = "2g",
spark.sql.warehouse.dir="C:\\Apps\\winutils\\winutils-master\\hadoop-2.7.1") # winutils path directory
)
sparkR.uiWebUrl()
blogdown::build_site()
waiting_70 <- sql("select * from df where waiting > 70")
df <- as.DataFrame(faithful)
str(df)
colnames(df)
createOrReplaceTempView(df, "df")
waiting_70 <- sql("select * from df where waiting > 70")
str(waiting_70)
df %>% collect() %>%
ggplot(aes(x = waiting, y = eruptions)) +
geom_point()
library(tidyverse)
df %>% collect() %>%
ggplot(aes(x = waiting, y = eruptions)) +
geom_point()
library(tidyverse)
.libPaths(c(file.path(Sys.getenv("SPARK_HOME"), "R", "lib"), .libPaths()))
library(SparkR)
SparkR::sparkR.session.stop()
library(tidyverse)
.libPaths(c(file.path(Sys.getenv("SPARK_HOME"), "R", "lib"), .libPaths()))
library(SparkR)
library(SparkR, lib.loc = c(file.path(Sys.getenv("SPARK_HOME"), "R", "lib")))
sparkR.session(#appName = "Blog",
enableHiveSupport = FALSE ,
master = "local[*]",
sparkHome = Sys.getenv("SPARK_HOME") , # this was the missing link!!
sparkConfig =
list(spark.driver.memory = "2g", # spark.executor.memory = "2g",
spark.sql.warehouse.dir="C:\\Apps\\winutils\\winutils-master\\hadoop-2.7.1") # winutils path directory
)
sparkR.uiWebUrl()
df <- as.DataFrame(faithful)
str(df)
colnames(df)
createOrReplaceTempView(df, "df")
waiting_70 <- sql("select * from df where waiting > 70")
str(waiting_70)
head(SparkR::collect(waiting_70), 10)
collect(summary(df))
SparkR::collect(SparkR::summary(df))
SparkR::corr(df, "waiting", "eruptions")
df %>% SparkR::collect() %>%
ggplot(aes(x = waiting, y = eruptions)) +
geom_point()
df %>% SparkR::collect() %>%
ggplot(aes(x = waiting, y = eruptions)) +
geom_point() +
geom_smooth()
head(df)
blogdown::build_site()
sparkR.uiWebUrl()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
waiting_avg <- SparkR::avg(df$waiting)
eruptions_avg <- SparkR::avg(df$eruptions)
df %>% SparkR::collect() %>%
ggplot(aes(x = waiting, y = eruptions)) +
geom_point() +
geom_smooth() +
geom_vline(xintercept = waiting_avg) +
geom_hline(yintercept = eruptions)
search()
waiting_avg <- SparkR::avg(df$waiting)
eruptions_avg <- SparkR::avg(df$eruptions)
df %>% SparkR::collect() %>%
ggplot(aes(x = waiting, y = eruptions)) +
geom_point() +
geom_smooth() +
geom_vline(xintercept = waiting_avg) +
geom_hline(yintercept = eruptions_avg)
waiting_avg <- SparkR::avg(df$waiting) %>% SparkR::collect()
waiting_avg
head(waiting_avg)
SparkR::avg(df$waiting)
head(SparkR::avg(df$waiting))
str(sf)
str(df)
avg(df$waiting)
collect(avg(df$waiting) )
SparkR::collect(avg(df$waiting) )
mean(df$eruptions)
head(df)
SparkR::avg(df,"waiting")
SparkR::collect(df$waiting) %>% mean()
collect(df$waiting)
waiting_avg <- SparkR::mean(df$waiting)
waiting_avg
waiting_avg <- SparkR::mean(df$waiting) %>% SparkR::collect()
SparkR::select(mean(df$waiting))
SparkR::select(SparkR::mean(df$waiting)) %>% SparkR::collect()
waiting_avg <- SparkR::select(df, SparkR::mean(df$waiting)) %>% SparkR::collect()
waiting_avg
waiting_avg <- SparkR::select(df, SparkR::mean(df$waiting)) %>% SparkR::collect()
eruptions_avg <- SparkR::select(df, SparkR::mean(df$eruptions)) %>% SparkR::collect()
df %>% SparkR::collect() %>%
ggplot(aes(x = waiting, y = eruptions)) +
geom_point() +
geom_smooth() +
geom_vline(xintercept = waiting_avg) +
geom_hline(yintercept = eruptions_avg)
waiting_avg
str(waiting_avg)
waiting_avg <- SparkR::select(df, SparkR::mean(df$waiting)) %>% SparkR::collect()
eruptions_avg <- SparkR::select(df, SparkR::mean(df$eruptions)) %>% SparkR::collect()
df %>% SparkR::collect() %>%
ggplot(aes(x = waiting, y = eruptions)) +
geom_point() +
geom_smooth() +
geom_vline(xintercept = waiting_avg$avg(waiting)) +
geom_hline(yintercept = eruptions_avg$`avg(eruptions)`)
waiting_avg <- SparkR::select(df, SparkR::mean(df$waiting)) %>% SparkR::collect()
eruptions_avg <- SparkR::select(df, SparkR::mean(df$eruptions)) %>% SparkR::collect()
df %>% SparkR::collect() %>%
ggplot(aes(x = waiting, y = eruptions)) +
geom_point() +
geom_smooth() +
geom_vline(xintercept = waiting_avg$`avg(waiting)`) +
geom_hline(yintercept = eruptions_avg$`avg(eruptions)`)
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
SparR::spark.session.stop
SparR::spark.session.stop()
SparkR::spark.session.stop()
SparkR::sparkR.session.stop()
rm(list=ls())
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown:::new_post_addin()
blogdown::serve_site()
blogdown::serve_site()
blogdown::hugo_build()
blogdown:::new_post_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown::hugo_build()
blogdown:::new_post_addin()
blogdown:::insert_image_addin()
install.packages("stringi")
blogdown::hugo_build()
blogdown::hugo_build()
blogdown::hugo_build()
install.packages(c("assertthat", "cli", "colorspace", "e1071", "fs", "git2r", "gtable", "highr", "httpuv", "JuliaCall", "lazyeval", "Matrix", "mgcv", "openssl", "pkgbuild", "purrr", "rgdal", "rlang", "rstudioapi", "tibble"))
blogdown::build_site()
install.packages("tidyverse")
install.packages("backports")
blogdown::build_site()
blogdown::build_site()
install.packages("pander")
# installing/loading the package:
if(!require(installr)) { install.packages("installr"); require(installr)} #load / install+load installr
# Installing pandoc
install.pandoc()
blogdown::build_site()
knitr::include_graphics("\images\Apache_folder_2018_05_15.png")
knitr::include_graphics("/images/Apache_folder_2018_05_15.png")
knitr::include_graphics("/public/images/Apache_folder_2018_05_15.png")
library("png", lib.loc="C:/Apps/R/R-3.5.0/library")
detach("package:png", unload=TRUE)
blogdown::build_site()
sparkR.session(
enableHiveSupport = FALSE ,
master = "local[*]",
sparkHome = Sys.getenv("SPARK_HOME") , # this was the missing link!!
sparkConfig =
list(spark.driver.memory = "2g",
spark.sql.warehouse.dir="C:\\Apps\\winutils\\winutils-master\\hadoop-2.7.1") # winutils path directory
)
library(SparkR, lib.loc = c(file.path(Sys.getenv("SPARK_HOME"), "R", "lib")))
sparkR.session(
enableHiveSupport = FALSE ,
master = "local[*]",
sparkHome = Sys.getenv("SPARK_HOME") , # this was the missing link!!
sparkConfig =
list(spark.driver.memory = "2g",
spark.sql.warehouse.dir="C:\\Apps\\winutils\\winutils-master\\hadoop-2.7.1") # winutils path directory
)
blogdown::hugo_build()
blogdown::hugo_build()
blogdown::hugo_build()
blogdown::hugo_build()
blogdown::hugo_build()
blogdown::hugo_build()
blogdown::hugo_build()
blogdown::hugo_build()
blogdown::hugo_build()
blogdown:::insert_image_addin()
getwd()
library(blogdown)
getwd()
print("hello world")
pandoc_version()
install.packages("rmarkdown")
install.packages("rmarkdown")
install.packages("rmarkdown")
install.packages("rmarkdown")
blogdown::build_site()
getwd()
unlink('content/post/2019-09-29-juliapro-on-jupyter_cache', recursive = TRUE)
install.packages("blogdown")
install.packages("blogdown")
install.packages("blogdown")
library(blogdown)
getwd()
getwd()
library(blogdown)
hugo_build()
hugo_build()
build_site()
library(blogdown)
build_site()
